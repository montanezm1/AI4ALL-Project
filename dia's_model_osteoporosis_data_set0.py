# -*- coding: utf-8 -*-
"""Dia's model osteoporosis-data-set0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1giFJ309_mqPgCb2pRqszxWdOJf_h_84x
"""

import pandas as pd
import numpy as np

from glob import glob

from google.colab import drive
drive.mount("/content/drive")

import os
from PIL import Image, ImageStat
import cv2
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader, random_split, WeightedRandomSampler
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import ReduceLROnPlateau
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
import seaborn as sns
from tqdm import tqdm

# ========== CONFIGURATION ==========
data_dir = "/content/drive/MyDrive/AI4ALL Group 11A/archive/OS Collected Data"
BATCH_SIZE = 16
NUM_WORKERS = 2
IMAGE_SIZE = (224, 224)
NUM_EPOCHS = 50
LEARNING_RATE = 0.0001
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

def advanced_image_cleaning(root_dir, image_size, min_brightness=20, max_brightness=235):
    """
    Comprehensive image cleaning with multiple quality checks
    """
    if not os.path.exists(root_dir):
        print(f"Error: Directory '{root_dir}' does not exist.")
        return

    removed_count = 0
    processed_count = 0

    for subfolder in os.listdir(root_dir):
        subfolder_path = os.path.join(root_dir, subfolder)
        if not os.path.isdir(subfolder_path):
            continue

        print(f"\nProcessing folder: {subfolder}")
        files = os.listdir(subfolder_path)

        for file in tqdm(files, desc=f"Cleaning {subfolder}"):
            file_path = os.path.join(subfolder_path, file)

            try:
                with Image.open(file_path) as img:
                    # Check 1: Valid image format
                    if img.mode not in ['L', 'RGB', 'RGBA']:
                        print(f"Invalid mode {img.mode}: {file_path}")
                        os.remove(file_path)
                        removed_count += 1
                        continue

                    # Check 2: Image size (too small = likely corrupt)
                    if img.size[0] < 50 or img.size[1] < 50:
                        print(f"Too small: {file_path}")
                        os.remove(file_path)
                        removed_count += 1
                        continue

                    # Convert to RGB
                    img = img.convert('RGB')

                    # Check 3: Brightness check (detect blank/overexposed images)
                    stat = ImageStat.Stat(img)
                    mean_brightness = sum(stat.mean) / len(stat.mean)

                    if mean_brightness < min_brightness or mean_brightness > max_brightness:
                        print(f"Abnormal brightness ({mean_brightness:.1f}): {file_path}")
                        os.remove(file_path)
                        removed_count += 1
                        continue

                    # Check 4: Variance check (detect completely uniform images)
                    variance = sum(stat.stddev) / len(stat.stddev)
                    if variance < 5:
                        print(f"Too uniform (variance={variance:.1f}): {file_path}")
                        os.remove(file_path)
                        removed_count += 1
                        continue

                    # Apply CLAHE for contrast enhancement (better for X-rays)
                    img_array = np.array(img)
                    lab = cv2.cvtColor(img_array, cv2.COLOR_RGB2LAB)
                    l, a, b = cv2.split(lab)
                    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
                    l = clahe.apply(l)
                    enhanced = cv2.merge([l, a, b])
                    enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2RGB)

                    # Resize and save
                    img_enhanced = Image.fromarray(enhanced)
                    img_enhanced = img_enhanced.resize(image_size, Image.LANCZOS)
                    img_enhanced.save(file_path, quality=95)
                    processed_count += 1

            except Exception as e:
                print(f"Error processing {file_path}: {e}")
                if os.path.exists(file_path):
                    os.remove(file_path)
                removed_count += 1

    print(f"\n✓ Cleaning complete!")
    print(f"  Processed: {processed_count} images")
    print(f"  Removed: {removed_count} images")

# Run advanced cleaning
print("Starting advanced data cleaning...")
advanced_image_cleaning(data_dir, IMAGE_SIZE)

# ========== DATA AUGMENTATION ==========
# Training transforms with augmentation
train_transform = transforms.Compose([
    transforms.RandomRotation(15),
    transforms.RandomHorizontalFlip(),
    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNet stats
])

# Validation/Test transforms (no augmentation)
val_test_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# ========== DATASET LOADING ==========
# Load full dataset
full_dataset = datasets.ImageFolder(data_dir, transform=None)

# Split dataset
dataset_size = len(full_dataset)
train_size = int(0.7 * dataset_size)
val_size = int(0.15 * dataset_size)
test_size = dataset_size - train_size - val_size

# Create indices for splitting
indices = list(range(dataset_size))
np.random.seed(42)
np.random.shuffle(indices)

train_indices = indices[:train_size]
val_indices = indices[train_size:train_size+val_size]
test_indices = indices[train_size+val_size:]

# Create datasets with appropriate transforms
class TransformDataset(torch.utils.data.Dataset):
    def __init__(self, dataset, indices, transform):
        self.dataset = dataset
        self.indices = indices
        self.transform = transform

    def __len__(self):
        return len(self.indices)

    def __getitem__(self, idx):
        image, label = self.dataset[self.indices[idx]]
        if self.transform:
            image = self.transform(image)
        return image, label

train_data = TransformDataset(full_dataset, train_indices, train_transform)
val_data = TransformDataset(full_dataset, val_indices, val_test_transform)
test_data = TransformDataset(full_dataset, test_indices, val_test_transform)

# Handle class imbalance with weighted sampling
train_labels = [full_dataset.targets[i] for i in train_indices]
class_counts = np.bincount(train_labels)
class_weights = 1.0 / class_counts
sample_weights = [class_weights[label] for label in train_labels]
sampler = WeightedRandomSampler(sample_weights, len(sample_weights))

# Create data loaders
train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, sampler=sampler, num_workers=NUM_WORKERS)
val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)
test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)

print(f"\nDataset split:")
print(f"  Training: {len(train_data)} images")
print(f"  Validation: {len(val_data)} images")
print(f"  Test: {len(test_data)} images")
print(f"  Classes: {full_dataset.classes}")
print(f"  Class distribution in training: {class_counts}")

# ========== MODEL ARCHITECTURE ==========
class OsteoporosisClassifier(nn.Module):
    def __init__(self, num_classes=2, pretrained=True):
        super(OsteoporosisClassifier, self).__init__()

        # Use EfficientNet-B3 (excellent accuracy-efficiency tradeoff)
        self.backbone = models.efficientnet_b3(pretrained=pretrained)

        # Replace classifier
        in_features = self.backbone.classifier[1].in_features
        self.backbone.classifier = nn.Sequential(
            nn.Dropout(p=0.3),
            nn.Linear(in_features, 512),
            nn.ReLU(),
            nn.Dropout(p=0.3),
            nn.Linear(512, num_classes)
        )

    def forward(self, x):
        return self.backbone(x)

model = OsteoporosisClassifier(num_classes=len(full_dataset.classes))
model = model.to(DEVICE)

# ========== TRAINING SETUP ==========
criterion = nn.CrossEntropyLoss()
optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)
scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)

# ========== TRAINING FUNCTIONS ==========
def train_epoch(model, loader, criterion, optimizer, device):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for images, labels in tqdm(loader, desc="Training", leave=False):
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()

    return running_loss / len(loader), 100. * correct / total

def validate(model, loader, criterion, device):
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0
    all_preds = []
    all_labels = []
    all_probs = []

    with torch.no_grad():
        for images, labels in tqdm(loader, desc="Validating", leave=False):
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)

            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            all_probs.extend(torch.softmax(outputs, dim=1)[:, 1].cpu().numpy())

    return running_loss / len(loader), 100. * correct / total, all_preds, all_labels, all_probs

# ========== TRAINING LOOP ==========
best_val_acc = 0
train_losses, val_losses = [], []
train_accs, val_accs = [], []

print("\nStarting training...")
for epoch in range(NUM_EPOCHS):
    print(f"\nEpoch {epoch+1}/{NUM_EPOCHS}")

    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, DEVICE)
    val_loss, val_acc, _, _, _ = validate(model, val_loader, criterion, DEVICE)

    train_losses.append(train_loss)
    val_losses.append(val_loss)
    train_accs.append(train_acc)
    val_accs.append(val_acc)

    print(f"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%")
    print(f"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%")

    # Learning rate scheduling
    scheduler.step(val_acc)

    # Save best model
    if val_acc > best_val_acc:
        best_val_acc = val_acc
        torch.save(model.state_dict(), 'best_osteoporosis_model.pth')
        print(f"✓ New best model saved! (Val Acc: {val_acc:.2f}%)")

# ========== EVALUATION ==========
print("\n" + "="*50)
print("FINAL EVALUATION ON TEST SET")
print("="*50)

model.load_state_dict(torch.load('best_osteoporosis_model.pth'))
test_loss, test_acc, test_preds, test_labels, test_probs = validate(model, test_loader, criterion, DEVICE)

print(f"\nTest Accuracy: {test_acc:.2f}%")
print(f"Test Loss: {test_loss:.4f}")

# Classification Report
print("\nClassification Report:")
print(classification_report(test_labels, test_preds, target_names=full_dataset.classes))

# Confusion Matrix
cm = confusion_matrix(test_labels, test_preds)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=full_dataset.classes, yticklabels=full_dataset.classes)
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

# ROC Curve
if len(full_dataset.classes) == 2:
    fpr, tpr, _ = roc_curve(test_labels, test_probs)
    auc = roc_auc_score(test_labels, test_probs)

    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.3f})')
    plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve')
    plt.legend()
    plt.grid(True)
    plt.show()
    print(f"\nAUC Score: {auc:.4f}")

# Training History
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

ax1.plot(train_losses, label='Train Loss')
ax1.plot(val_losses, label='Val Loss')
ax1.set_xlabel('Epoch')
ax1.set_ylabel('Loss')
ax1.set_title('Training and Validation Loss')
ax1.legend()
ax1.grid(True)

ax2.plot(train_accs, label='Train Acc')
ax2.plot(val_accs, label='Val Acc')
ax2.set_xlabel('Epoch')
ax2.set_ylabel('Accuracy (%)')
ax2.set_title('Training and Validation Accuracy')
ax2.legend()
ax2.grid(True)

plt.tight_layout()
plt.show()

print("\n✓ Training complete!")